{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a83155aa",
   "metadata": {},
   "source": [
    "# Sound Classification with CNN and Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61fa14c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ae61cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, Dense, MaxPool2D, Dropout\n",
    "from tensorflow.keras.utils import to_categorical \n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b277eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "import glob \n",
    "import skimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88edf6b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1120, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slice_file_name</th>\n",
       "      <th>fold</th>\n",
       "      <th>classID</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>purring (1).wav</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>purring</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>purring (2).wav</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>purring</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>purring (3).wav</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>purring</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>purring (4).wav</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>purring</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>purring (5).wav</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>purring</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   slice_file_name  fold  classID    class\n",
       "0  purring (1).wav     1        0  purring\n",
       "1  purring (2).wav     1        0  purring\n",
       "2  purring (3).wav     1        0  purring\n",
       "3  purring (4).wav     1        0  purring\n",
       "4  purring (5).wav     1        0  purring"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata = pd.read_csv('C:/Users/user/PycharmProjects/pythonProject/CatSound/metadata/cat2.csv')\n",
    "print(metadata.shape)\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66818524",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "classID\n",
       "0     [purring]\n",
       "1        [meow]\n",
       "2    [grooming]\n",
       "3    [drinking]\n",
       "4          [wc]\n",
       "5      [eating]\n",
       "Name: class, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = metadata.groupby('classID')['class'].unique()\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63b5525b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extractor(path):\n",
    "    data, simple_rate = librosa.load(path)\n",
    "    data = librosa.feature.mfcc(data,n_mfcc=128)\n",
    "    data = np.mean(data,axis=1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143ecc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature extraction with mfcc\n",
    "x, y = [], []\n",
    "extracted_features=[]\n",
    "for i,rows in tqdm(metadata.iterrows()):\n",
    "    path = 'C:/Users/user/PycharmProjects/pythonProject/CatSound/audio/' + 'fold' + str(rows['fold']) + '/' + str(rows['slice_file_name'])\n",
    "    x.append(feature_extractor(path))\n",
    "    y.append(rows['classID'])\n",
    "    fe = feature_extractor(path)\n",
    "    final_class_labels=rows['class']\n",
    "    extracted_features.append([fe,final_class_labels])\n",
    "x = np.array(x)\n",
    "y = np.array(y)\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "854e0234",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-312.18478, 125.071014, -64.47501, 56.468628,...</td>\n",
       "      <td>purring</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-408.58997, 146.62447, 32.391697, 36.671593, ...</td>\n",
       "      <td>purring</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-440.81326, 190.86948, -21.095238, -6.7931995...</td>\n",
       "      <td>purring</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-373.53268, 150.26164, 44.241188, 31.615002, ...</td>\n",
       "      <td>purring</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-578.2753, 163.7805, 61.469208, 17.083605, -3...</td>\n",
       "      <td>purring</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             feature    class\n",
       "0  [-312.18478, 125.071014, -64.47501, 56.468628,...  purring\n",
       "1  [-408.58997, 146.62447, 32.391697, 36.671593, ...  purring\n",
       "2  [-440.81326, 190.86948, -21.095238, -6.7931995...  purring\n",
       "3  [-373.53268, 150.26164, 44.241188, 31.615002, ...  purring\n",
       "4  [-578.2753, 163.7805, 61.469208, 17.083605, -3...  purring"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#each audio has mfcc matrix\n",
    "extracted_features_df=pd.DataFrame(extracted_features,columns=['feature','class'])\n",
    "extracted_features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e60f8ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1120, 6)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = to_categorical(y)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e96b3759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of samples for Train set : 806\n",
      "Number of samples for Validation set : 202\n",
      "Number of samples for Test set : 112\n"
     ]
    }
   ],
   "source": [
    "xtrainval, xtest, ytrainval, ytest = train_test_split(x,y,test_size=0.1,stratify=y,random_state=387)\n",
    "xtrain, xvalid, ytrain, yvalid = train_test_split(xtrainval,ytrainval,test_size=0.2,stratify=ytrainval,random_state=387)\n",
    "print('\\nNumber of samples for Train set :',xtrain.shape[0])\n",
    "print('Number of samples for Validation set :',xvalid.shape[0])\n",
    "print('Number of samples for Test set :',xtest.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8965e06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain = xtrain.reshape(806, 16, 8, 1)\n",
    "xtest = xtest.reshape(112, 16, 8, 1)\n",
    "xvalid = xvalid.reshape(202, 16, 8, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a02eee95",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = (16, 8, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3cd36335",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kerastuner.tuners import RandomSearch\n",
    "from kerastuner.engine.hyperparameters import HyperParameters\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import keras_tuner\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e1db05a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):  # random search passes this hyperparameter() object \n",
    "    model = Sequential() # tuning: number of hidden layers, number of neurons, dropout rate, activation function\n",
    "    \n",
    "    model.add(Conv2D(hp.Int('input_units',\n",
    "                                min_value=32,\n",
    "                                max_value=256,\n",
    "                                step=32), (3, 3), padding = \"same\", activation = hp.Choice(\"activation\", [\"relu\", \"tanh\"]), input_shape = input_dim))\n",
    "    model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "    for i in range(hp.Int('n_layers', 1, 4)):  \n",
    "        model.add(Conv2D(hp.Int(f'conv_{i}_units',\n",
    "                                min_value=32,\n",
    "                                max_value=256,\n",
    "                                step=32), (3, 3), padding = \"same\", activation = hp.Choice(\"activation\", [\"relu\", \"tanh\"])))\n",
    "    model.add(Dropout(rate=hp.Float(\n",
    "                    'dropout',\n",
    "                    min_value=0.0,\n",
    "                    max_value=0.5,\n",
    "                    default=0.25,\n",
    "                    step=0.05)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024, activation = hp.Choice(\"activation\", [\"relu\", \"tanh\"])))\n",
    "    model.add(Dense(6, activation = \"softmax\"))\n",
    "    \n",
    "    model.compile(optimizer='adam',\n",
    "                  loss=\"categorical_crossentropy\",\n",
    "                  metrics=[\"accuracy\"])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a7928d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9c7de15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointer = ModelCheckpoint(filepath='saved_models/cat_model_1.hdf5', \n",
    "                               verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c3b61a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=5,  # how many model variations to test?\n",
    "    executions_per_trial=3,  # how many trials per variation? (same model could perform differently)\n",
    "    overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3a55ff54",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 00m 57s]\n",
      "val_accuracy: 0.9966996510823568\n",
      "\n",
      "Best val_accuracy So Far: 1.0\n",
      "Total elapsed time: 00h 12m 39s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner.search(x=xtrain,\n",
    "             y=ytrain,\n",
    "             verbose=10, # just slapping this here bc jupyter notebook. The console out was getting messy.\n",
    "             epochs=50,\n",
    "             batch_size=20,\n",
    "             validation_data=(xvalid, yvalid)\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d594657d",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hp=tuner.get_best_hyperparameters()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e6d5d81e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 16, 8, 224)        2240      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 4, 224)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 4, 224)         451808    \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 8, 4, 224)         451808    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 8, 4, 224)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 7168)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              7341056   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 6)                 6150      \n",
      "=================================================================\n",
      "Total params: 8,253,062\n",
      "Trainable params: 8,253,062\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "21/21 [==============================] - 1s 19ms/step - loss: 9.1049 - accuracy: 0.3168 - val_loss: 2.1524 - val_accuracy: 0.4938\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.15241, saving model to saved_models\\cat_model_1.hdf5\n",
      "Epoch 2/50\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.7391 - accuracy: 0.7562 - val_loss: 0.2058 - val_accuracy: 0.9630\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.15241 to 0.20576, saving model to saved_models\\cat_model_1.hdf5\n",
      "Epoch 3/50\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 0.2104 - accuracy: 0.9410 - val_loss: 0.1175 - val_accuracy: 0.9444\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.20576 to 0.11751, saving model to saved_models\\cat_model_1.hdf5\n",
      "Epoch 4/50\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.1289 - accuracy: 0.9643 - val_loss: 0.0472 - val_accuracy: 0.9877\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.11751 to 0.04721, saving model to saved_models\\cat_model_1.hdf5\n",
      "Epoch 5/50\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 0.0564 - accuracy: 0.9845 - val_loss: 0.0166 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.04721 to 0.01659, saving model to saved_models\\cat_model_1.hdf5\n",
      "Epoch 6/50\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 0.0311 - accuracy: 0.9938 - val_loss: 0.0357 - val_accuracy: 0.9938\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.01659\n",
      "Epoch 7/50\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.0412 - accuracy: 0.9876 - val_loss: 0.0345 - val_accuracy: 0.9938\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.01659\n",
      "Epoch 8/50\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.0719 - accuracy: 0.9767 - val_loss: 0.0353 - val_accuracy: 0.9877\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.01659\n",
      "Epoch 9/50\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 0.0336 - accuracy: 0.9938 - val_loss: 0.0187 - val_accuracy: 0.9938\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.01659\n",
      "Epoch 10/50\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.0104 - accuracy: 0.9969 - val_loss: 0.0159 - val_accuracy: 0.9938\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.01659 to 0.01594, saving model to saved_models\\cat_model_1.hdf5\n",
      "Epoch 11/50\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.0087 - val_accuracy: 0.9938\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.01594 to 0.00872, saving model to saved_models\\cat_model_1.hdf5\n",
      "Epoch 12/50\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0056 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.00872 to 0.00556, saving model to saved_models\\cat_model_1.hdf5\n",
      "Epoch 13/50\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.00556 to 0.00508, saving model to saved_models\\cat_model_1.hdf5\n",
      "Epoch 14/50\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0052 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.00508\n",
      "Epoch 15/50\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.00508 to 0.00442, saving model to saved_models\\cat_model_1.hdf5\n",
      "Epoch 16/50\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.00442\n",
      "Epoch 17/50\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 9.6069e-04 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.00442 to 0.00387, saving model to saved_models\\cat_model_1.hdf5\n",
      "Epoch 18/50\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 8.7054e-04 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.00387\n",
      "Epoch 19/50\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 7.8192e-04 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.00387\n",
      "Epoch 20/50\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 7.2785e-04 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.00387\n",
      "Epoch 21/50\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 6.8433e-04 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.00387\n",
      "Epoch 22/50\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 6.3979e-04 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.00387 to 0.00356, saving model to saved_models\\cat_model_1.hdf5\n",
      "Epoch 23/50\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 5.7626e-04 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.00356\n",
      "Epoch 24/50\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 5.5676e-04 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.00356\n",
      "Epoch 25/50\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 5.1104e-04 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.00356 to 0.00312, saving model to saved_models\\cat_model_1.hdf5\n",
      "Epoch 26/50\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 4.7789e-04 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.00312\n",
      "Epoch 27/50\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 4.5440e-04 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.00312\n",
      "Epoch 28/50\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 4.1693e-04 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.00312 to 0.00298, saving model to saved_models\\cat_model_1.hdf5\n",
      "Epoch 29/50\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 4.0895e-04 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.00298\n",
      "Epoch 30/50\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 3.6670e-04 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.00298\n",
      "Epoch 31/50\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 3.6272e-04 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.00298\n",
      "Epoch 32/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 11ms/step - loss: 3.3782e-04 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.00298 to 0.00298, saving model to saved_models\\cat_model_1.hdf5\n",
      "Epoch 33/50\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 3.2303e-04 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.00298 to 0.00287, saving model to saved_models\\cat_model_1.hdf5\n",
      "Epoch 34/50\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 3.0886e-04 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.00287 to 0.00281, saving model to saved_models\\cat_model_1.hdf5\n",
      "Epoch 35/50\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 2.9850e-04 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.00281\n",
      "Epoch 36/50\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 2.7413e-04 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.00281 to 0.00231, saving model to saved_models\\cat_model_1.hdf5\n",
      "Epoch 37/50\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 2.6686e-04 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.00231\n",
      "Epoch 38/50\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 2.4515e-04 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.00231\n",
      "Epoch 39/50\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 2.3395e-04 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.00231\n",
      "Epoch 40/50\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 2.2783e-04 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.00231\n",
      "Epoch 41/50\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 2.2113e-04 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.00231 to 0.00212, saving model to saved_models\\cat_model_1.hdf5\n",
      "Epoch 42/50\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 2.0900e-04 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.00212 to 0.00201, saving model to saved_models\\cat_model_1.hdf5\n",
      "Epoch 43/50\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 2.1057e-04 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.00201\n",
      "Epoch 44/50\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 1.9948e-04 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.00201\n",
      "Epoch 45/50\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 1.8742e-04 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.00201 to 0.00199, saving model to saved_models\\cat_model_1.hdf5\n",
      "Epoch 46/50\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 1.8128e-04 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.00199 to 0.00189, saving model to saved_models\\cat_model_1.hdf5\n",
      "Epoch 47/50\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 1.7469e-04 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.00189\n",
      "Epoch 48/50\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 1.7210e-04 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.00189\n",
      "Epoch 49/50\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 1.5568e-04 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.00189 to 0.00164, saving model to saved_models\\cat_model_1.hdf5\n",
      "Epoch 50/50\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 1.6155e-04 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.00164\n"
     ]
    }
   ],
   "source": [
    "h_model = tuner.hypermodel.build(best_hp)\n",
    "h_model.summary()\n",
    "history=h_model.fit(xtrain, ytrain, epochs=50, validation_split=0.2, callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9e39357f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, 'y', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c50bcbf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAsf0lEQVR4nO3de3wU5fn38c+VhCRAEIWAIMFCFVGsghKxSn8tWm1B/UFRW0Hbij2gqK3aWqt9rCJqn9raSlutfWg9VduCpyJaPJ+rVokKingAKUIQNKIcAiQhyfX8MZMw2WzCghmWZL7v1ysvdg47e80m7LXXfc/ct7k7IiKSXDnZDkBERLJLiUBEJOGUCEREEk6JQEQk4ZQIREQSTolARCThlAikGTN70MxOb+t9s8nMlpnZMTEc181s3/Dxn8zs55nsuwOvc5qZPbKjcYq0xnQfQcdgZpWRxS5ANVAXLp/p7n/b+VHtOsxsGfA9d3+sjY/rwCB3X9JW+5rZAOC/QCd3r22TQEVakZftAKRtuHtRw+PWPvTMLE8fLrKr0N/jrkFNQx2cmY0ys3Iz+6mZrQZuMbM9zOwBM6sws0/CxyWR5zxlZt8LH08ys3+b2bXhvv81szE7uO9AM3vGzDaY2WNmdoOZ3dFC3JnEeKWZPRce7xEzK45s/5aZvWdma8zs/7Ty/hxuZqvNLDeybryZvRY+HmFmL5jZWjNbZWbXm1l+C8e61cyuiiz/JHzO+2b2nZR9jzezV81svZmtMLOpkc3PhP+uNbNKMzui4b2NPP9IM5tnZuvCf4/M9L3Zzve5h5ndEp7DJ2Y2O7JtnJnND8/hXTMbHa5v0gxnZlMbfs9mNiBsIvuumS0HngjX3xX+HtaFfyMHRp7f2cx+E/4+14V/Y53N7F9m9oOU83nNzManO1dpmRJBMvQBegCfASYT/N5vCZf3BjYD17fy/MOBt4Fi4FfATWZmO7Dv34GXgJ7AVOBbrbxmJjGeCpwB9AbygQsBzGwIcGN4/L3C1yshDXd/EdgIHJ1y3L+Hj+uAC8LzOQL4MnB2K3ETxjA6jOdYYBCQ2j+xEfg2sDtwPDDFzL4Wbvti+O/u7l7k7i+kHLsH8C/g9+G5/Rb4l5n1TDmHZu9NGtt6n28naGo8MDzWdWEMI4C/Aj8Jz+GLwLIWXiOdLwEHAF8Nlx8keJ96A68A0abMa4HhwJEEf8cXAfXAbcA3G3Yys6FAP4L3RraHu+ung/0Q/Ic8Jnw8CqgBClvZfxjwSWT5KYKmJYBJwJLIti6AA322Z1+CD5laoEtk+x3AHRmeU7oYL40snw08FD6+DJgZ2dY1fA+OaeHYVwE3h4+7EXxIf6aFfc8H/hlZdmDf8PGtwFXh45uBX0b22y+6b5rjTgeuCx8PCPfNi2yfBPw7fPwt4KWU578ATNrWe7M97zPQl+ADd480+/2/hnhb+/sLl6c2/J4j5/bZVmLYPdynO0Gi2gwMTbNfIfAJQb8LBAnjj3H8n+roP6oIkqHC3asaFsysi5n9v7DUXk/QFLF7tHkkxeqGB+6+KXxYtJ377gV8HFkHsKKlgDOMcXXk8aZITHtFj+3uG4E1Lb0Wwbf/E82sADgReMXd3wvj2C9sLlkdxvELgupgW5rEALyXcn6Hm9mTYZPMOuCsDI/bcOz3Uta9R/BtuEFL700T23if+xP8zj5J89T+wLsZxptO43tjZrlm9suweWk9WyuL4vCnMN1rhX/Ts4BvmlkOMJGggpHtpESQDKmXhv0YGAwc7u67sbUpoqXmnrawCuhhZl0i6/q3sv+niXFV9Njha/ZsaWd3X0TwQTqGps1CEDQxvUXwrXM34Gc7EgNBRRT1d2AO0N/duwN/ihx3W5fyvU/QlBO1N7Ayg7hStfY+ryD4ne2e5nkrgH1aOOZGgmqwQZ80+0TP8VRgHEHzWXeCqqEhho+AqlZe6zbgNIImu02e0owmmVEiSKZuBOX22rC9+fK4XzD8hl0GTDWzfDM7AvjfmGK8GzjBzL4QduxOY9t/638HziP4ILwrJY71QKWZ7Q9MyTCGO4FJZjYkTESp8Xcj+LZdFba3nxrZVkHQJPPZFo49F9jPzE41szwzOwUYAjyQYWypcaR9n919FUHb/R/DTuVOZtaQKG4CzjCzL5tZjpn1C98fgPnAhHD/UuDkDGKoJqjauhBUXQ0x1BM0s/3WzPYKq4cjwuqN8IO/HvgNqgZ2mBJBMk0HOhN82/oP8NBOet3TCDpc1xC0y88i+ABIZzo7GKO7vwGcQ/DhvoqgHbl8G0/7B0EH5hPu/lFk/YUEH9IbgD+HMWcSw4PhOTwBLAn/jTobmGZmGwj6NO6MPHcTcDXwnAVXK30+5dhrgBMIvs2vIeg8PSEl7kxNp/X3+VvAFoKq6EOCPhLc/SWCzujrgHXA02ytUn5O8A3+E+AKmlZY6fyVoCJbCSwK44i6EHgdmAd8DFxD08+uvwIHEfQ5yQ7QDWWSNWY2C3jL3WOvSKTjMrNvA5Pd/QvZjqW9UkUgO42ZHWZm+4RNCaMJ2oVnZzksacfCZrezgRnZjqU9UyKQnakPwaWNlQTXwE9x91ezGpG0W2b2VYL+lA/YdvOTtEJNQyIiCaeKQEQk4drdoHPFxcU+YMCAbIchItKuvPzyyx+5e69029pdIhgwYABlZWXZDkNEpF0xs9S70RupaUhEJOGUCEREEk6JQEQk4ZQIREQSTolARCThYksEZnazmX1oZgtb2G5m9nszWxJOL3doXLGIiEjL4qwIbgVGt7J9DMHUdIMIpk+8McZYRESkBbHdR+Duz5jZgFZ2GQf81YMxLv5jZrubWd9wDPT26emnYdEi+PKXYdAgaHFa33i5OzU1q9m8eTGbNy+mqmoFwZDtobp6Cl57n8L/vIdVbclKjCKy/TqN/y5FR53e5sfN5g1l/Wg6lV95uK5ZIjCzyQRVA3vvnTrR0y7g3Xfhwgth9uyt6/bZB447DsaMgVGjoHPnNn1Jd2fLlgo2b17Mpk2LGz/0g58l1NVVNtm/0zrY4yXo+RL0eAk6rQ+Pk51cJSI7YO1eJdDBEkHG3H0G4TCzpaWlu84oeevXw9VXw/Tp0KlT8Pikk+Dxx+HBB+Evf4E//AEv6MSmg/cgt0sxnfKLyc2JJIW8PPj854OkMWwY5LTQWrduHf7Iw1TefQ31y5dQV78RvA6AgvCnR24XcnO6kJPbg9yc/uQ0LK/dhL38CrhDr14wbnTwel/5CtajR8xvkoi0lT1iOm42E8FKms7pWsKOzbm689XXw623ws9+Bh98AKefDr/4Bey1V7B98GA2n3Ec7y+dzqaH/sweL2xit7c/pq7yQ2qAnJzO5OXtTl7e7uRW52D/+hf8/Oew555BBXHccXDssbBiBcydC3Pn4s8/j9XW0rkrVA/sRn5uMTk5hZGfAswN6gh+GtVAUTe4/PLguMOHt5xsRCSRspkI5gDnmtlM4HBgXbvoH3CH8eNhzhw44gi4/3447LBwk7Nu3TOUl/+Ojz66DzB6jT6Jbt87j267HcHmze+wZs1cPv54LmvXPo37KnJzd6N//rmUvLE/eY88C/fdFySZiLqDB7P61K58WLqRPl+7gb79J+/88xaRDiu2+QjM7B/AKKCYYOKIy4FOAO7+JzMz4HqCK4s2AWe4+zZHkystLfWsDjr35JNw9NHBN+zLL2/sEK6vr2bRotP46KN7yMvrwV57TWavvc6msLB/2sPU1m5g7don+OCDf1BRcSe5uV3p1+88+vf9IZ1eWRw0L/XrR8Xwzby5/iLy8nrwuc/dy267jdiZZysiHYSZvezupWm3tbeJabKeCEaNgnfegaVLobAQgLq6jSxc+DU++eQxBg68mpKS88nN7ZLxITduXMSyZVeECWE3SkrOp1+/H7B8+S8oL7+O7t2/yIEH3kl+/p4xnZSIdHStJYJ20Vm8y3j66eBn+vTGJLBlyye8/vrxrF//Ivvvfyt9+mx/j37XrkM48MBZVFZeyrJlV/Dee9N4772rgHr69fsh++xzLTk5ndr2XEREQqoItsfRR8ObbwbVQOfO1NR8wIIFX2XTpkUMGTKTXr1ObJOX2bBhPuXl19Gjx1fYc8/T2uSYIpJsqgjawjPPBP0D110HnTtTVbWcBQuOpbp6BQcd9AA9enylzV6qW7dhHHDAbW12PBGR1igRZOqKK4LLO888k02b3mHBgmOorV3P0KGP0r37yGxHJyKyw3RB+Ycfwtix8OKLLe/z7LPwxBNw0UVsZjXz54+ivr6KYcOeVBIQkXZPiWD+/OBegFGj4N570+9zxRXQuzc13xnPggXHUl9fxdChT9Ct2yE7M1IRkVgoEVSGY/L06QMnnwy/+U1w01iD556Dxx+n7sc/YMHi8dTUrOKgg+ZSVPS57MQrItLGlAgaEsH99wfjBF14IZxzDtTWBuuvuALv1YuFX3iQTZsW8bnP3Uv37p/PXrwiIm1MiaAhERQXw6xZcNFFcOONQb/BI4/Ao4+y+pvFfFLzAgcccDs9enw1u/GKiLQxXTW0cWPwb1FRMBjbNdcEQ0iffTb+0EPU7VHA4mPfZNCgP9K79ynZjVVEJAaqCBoqgi6RISEmT4YHHqC+ewFLv13N3gdMo1+/KdmJT0QkZqoIKiuha9dmQzPXHnME/76nij57ncFnPnNploITEYmfKoKNG4NEkKKqajnkQI8eY7AsTTkpIrIzKBFUVgb9Aymqq5cDUFi4C06NKSLShpQIWkgEVVVBIigoSD+fgIhIR6FE0NBHkKK6ejlmncjP75OFoEREdh4lgo0bW6gIVlBQUIKZ3iIR6dj0KddKH0FBgfoHRKTjUyJopY+gpfmGRUQ6EiWCNJePutdRXV2uikBEEiHWRGBmo83sbTNbYmYXp9n+GTN73MxeM7OnzKwkznjSSlMR1NSsBup06aiIJEJsicDMcoEbgDHAEGCimQ1J2e1a4K/ufjAwDfi/ccWTVl0dbN7cLBHo0lERSZI4K4IRwBJ3X+ruNcBMYFzKPkOAJ8LHT6bZHq+GAedSmoYabiZT05CIJEGciaAfsCKyXB6ui1oAnBg+Hg90M7OeqQcys8lmVmZmZRUVFW0XYXTk0YiGikBNQyKSBNnuLL4Q+JKZvQp8CVgJ1KXu5O4z3L3U3Ut79erVdq/eMPJoSiKorl5Bbm538vJ2a7vXEhHZRcU5+uhKINrIXhKua+Tu7xNWBGZWBJzk7mtjjKmpFhKBLh0VkSSJsyKYBwwys4Fmlg9MAOZEdzCzYtt66+4lwM0xxtNcK30E6h8QkaSILRG4ey1wLvAw8CZwp7u/YWbTzGxsuNso4G0zewfYE7g6rnjSarUiUCIQkWSIdWIad58LzE1Zd1nk8d3A3XHG0Ko0iaCubhO1tWtUEYhIYmS7szi7GhJBpGmoujq40En3EIhIUiQ7EaS5fFSXjopI0iQ7EaRpGtLNZCKSNEoEZtC5c+OqqqoVgFFQkHrvm4hIx5TsRNAw8mhkcvrq6uXk5/clJ6dTFgMTEdl5kp0I0ow8qktHRSRplAiaDS+hm8lEJFmUCCKXjro71dUrVBGISKIkOxGkTFy/ZctH1NdX6R4CEUmUZCeClKYhXToqIkmkRKCbyUQk4ZKdCFImrt86vIQSgYgkR7ITQZqKICenkE6dmk2SJiLSYSkRpPQRFBTsjUVuMBMR6eiSmwhqa6G6uknTkG4mE5EkSm4iSDPyaHX1Cl06KiKJk9xEkDLyaH19DTU1q9RRLCKJo0QQJoLq6pWAq2lIRBInuYkgZeJ63UwmIkmV3ESQUhEE8xBAYaH6CEQkWWJNBGY22szeNrMlZnZxmu17m9mTZvaqmb1mZsfFGU8TzZqGGioCJQIRSZbYEoGZ5QI3AGOAIcBEMxuSstulwJ3ufggwAfhjXPE0kzJxfVXVcjp1KiY3t8tOC0FEZFcQZ0UwAlji7kvdvQaYCYxL2ceB3cLH3YH3Y4ynqZTLRzUPgYgkVZyJoB+wIrJcHq6Lmgp808zKgbnAD9IdyMwmm1mZmZVVVFS0TXTNmoZ0D4GIJFO2O4snAre6ewlwHHC7mTWLyd1nuHupu5f26tWrbV65WWex7ioWkWSKMxGsBKJfsUvCdVHfBe4EcPcXgEKgOMaYttq4EXJyoKCA2tp11NWtV9OQiCRSnIlgHjDIzAaaWT5BZ/CclH2WA18GMLMDCBJBG7X9bEPDgHNmmodARBIttkTg7rXAucDDwJsEVwe9YWbTzGxsuNuPge+b2QLgH8Akd/e4YmoiMvLo1nkI1EcgIsmTF+fB3X0uQSdwdN1lkceLgJFxxtCiyMT1qghEJMmy3VmcPZGJ66url2OWR35+nywHJSKy8yU3EUSahqqqllNQUEJwD5yISLIoEaB7CEQk2ZKbCCIT1+uuYhFJsuQmgrAicK+jurpcHcUikliJTwQ1NR/gXquKQEQSK/GJYOulo+ojEJFkSmYiqKmBLVuga1dqaz8BIC+vZ5aDEhHJjmQmgsgQ1HV1weBzublFWQxIRCR7kpkIIiOP1tVtACAvr1sWAxIRyZ5kJoLIxPWqCEQk6ZKZCNJUBLm5qghEJJmUCOoqMetETk5+dmMSEcmSxCeC2toNqgZEJNGSmQhS+gjUPyAiSbbNRGBm/5tuHuF2LaWPQBWBiCRZJh/wpwCLzexXZrZ/3AHtFCl9BKoIRCTJtpkI3P2bwCHAu8CtZvaCmU02s/b7NbpJ09AG3UMgIomWUZOPu68H7gZmAn2B8cArZvaDGGOLT2Ul5OVBfr4qAhFJvEz6CMaa2T+Bp4BOwAh3HwMMJZh8vv1pmJTGTH0EIpJ4mUxefxJwnbs/E13p7pvM7LutPdHMRgO/A3KBv7j7L1O2XwccFS52AXq7++4Zxr7jIrOTqSIQkaTLJBFMBVY1LJhZZ2BPd1/m7o+39CQLJgC+ATgWKAfmmdkcd1/UsI+7XxDZ/wcEfRHxi8xOpvsIRCTpMukjuAuojyzXheu2ZQSwxN2XunsNQf/CuFb2nwj8I4PjfnphRVBfvwX3alUEIpJomSSCvPCDHIDwcSbjMfQDVkSWy8N1zZjZZ4CBwBMtbJ9sZmVmVlZRUZHBS29DmAi2DjinikBEkiuTRFBhZmMbFsxsHPBRG8cxAbjb3evSbXT3Ge5e6u6lvXr1+vSvFjYNaeRREZHM+gjOAv5mZtcDRvAt/9sZPG8lEJ3/sSRcl84E4JwMjtk2Kithn300F4GICBkkAnd/F/i8mRWFy5UZHnseMMjMBhIkgAnAqak7hXcr7wG8kGnQn1qzpiFVBCKSXJlUBJjZ8cCBQKGZAeDu01p7jrvXmtm5wMMEl4/e7O5vmNk0oMzd54S7TgBmurvv4Dlsv8ZEoLkIRES2mQjM7E8E1/gfBfwFOBl4KZODu/tcYG7KustSlqdmGGvbcFcfgYhIRCadxUe6+7eBT9z9CuAIYL94w4pRTQ3U1jbORQCqCEQk2TJJBFXhv5vMbC9gC8F4Q+1TysijoIpARJItkz6C+81sd+DXwCuAA3+OM6hYNSSCrl2pq/sYUEUgIsnWaiIIJ6R53N3XAveY2QNAobuv2xnBxaJhCOqiIurqlgOQm9sliwGJiGRXq01D7l5PMF5Qw3J1u04CkGZ2siI62gRsIiLbI5NPwMfN7CRruG60vdPsZCIiTWSSCM4kGGSu2szWm9kGM1sfc1zxSZmdTP0DIpJ0mdxZ3LE+KaMVwRZVBCIimdxQ9sV061Mnqmk3IomgtkIVgYhIJpeP/iTyuJBgnoGXgaNjiShu0ctHV1eSn79nduMREcmyTJqG/je6bGb9gelxBRS7Zn0E+2Y3HhGRLNuR6ybLgQPaOpCdprIS8vMhP19XDYmIkFkfwR8I7iaGIHEMI7jDuH1qMnH9Bs1FICKJl0kfQVnkcS3wD3d/LqZ44heOPOruqghERMgsEdwNVDVMI2lmuWbWxd03xRtaTBonrt8EuK4aEpHEy+jOYqBzZLkz8Fg84ewEmp1MRKSJTBJBYXR6yvBx+x2lrbISunbVXAQiIqFMEsFGMzu0YcHMhgOb4wspZhs3plQESgQikmyZ9BGcD9xlZu8DBvQBTokzqFg1m69YTUMikmyZ3FA2z8z2BwaHq9529y3xhhWjlD4CXT4qIkm3zaYhMzsH6OruC919IVBkZmdncnAzG21mb5vZEjO7uIV9vmFmi8zsDTP7+/aFvwMaJ65XRSAiApn1EXw/nKEMAHf/BPj+tp5kZrkEk9qMAYYAE81sSMo+g4BLgJHufiBBM1R83NNcNaSKQESSLZNEkBudlCb8gM/P4HkjgCXuvtTda4CZwLiUfb4P3BAmF9z9w8zC3kFVVVBfrz4CEZGITBLBQ8AsM/uymX0Z+AfwYAbP6wesiCyXh+ui9gP2M7PnzOw/ZjY63YHMbLKZlZlZWUVFRQYv3YImE9frPgIREcjsqqGfApOBs8Ll1wiuHGqr1x8EjAJKgGfM7KBoUxSAu88AZgCUlpY6OyoycX1t7UrM8snJyaS4ERHpuLZZEYQT2L8ILCNo7jkaeDODY68E+keWS8J1UeXAHHff4u7/Bd4hSAzxaDZfsfoHRERaTARmtp+ZXW5mbwF/AJYDuPtR7n59BseeBwwys4Fmlg9MAOak7DOboBrAzIoJmoqWbu9JZKxJItigZiEREVpvGnoLeBY4wd2XAJjZBZke2N1rzexc4GEgF7jZ3d8ws2lAmbvPCbd9xcwWAXXAT9x9zQ6ey7Y1mZSmUvcQiIjQeiI4keBb/JNm9hDBVT/Wyv7NuPtcYG7Kussijx34UfgTP1UEIiLNtNg05O6z3X0CsD/wJME1/r3N7EYz+8pOiq9tNUsEqghERDLpLN7o7n8P5y4uAV4luJKo/Um5fFQVgYjIds5Z7O6fuPsMd/9yXAHFqsnlo6oIRERgxyavb79UEYiINJO8RFBYCHl56iMQEQklKxGEI4/W19fgXqOKQESEpCUCzUUgItJMohOBKgIRkSQmgiaT0qgiEBFJViJoNnG9KgIRkWQlgrBpqLZWFYGISINEJgJVBCIiWyUrETSbuF4VgYhIshKBKgIRkWaSkwjq6yOdxUFFoPsIRESSlAg2bwb3SEVg5OR0yXZUIiJZl5xE0GR2smBSGrPtmmdHRKRDSk4iaDZxvfoHREQgoYlAcxGIiGyVnESQMnG9KgIRkUCsicDMRpvZ22a2xMwuTrN9kplVmNn88Od7sQWj+YpFRNLKi+vAZpYL3AAcC5QD88xsjrsvStl1lrufG1ccjaKJoLaS/Py+sb+kiEh7EGdFMAJY4u5L3b0GmAmMi/H1WpdSEegeAhGRQJyJoB+wIrJcHq5LdZKZvWZmd5tZ/3QHMrPJZlZmZmUVFRU7Fo36CERE0sp2Z/H9wAB3Pxh4FLgt3U7uPsPdS929tFevXjv2SuojEBFJK85EsBKIfsMvCdc1cvc17l4dLv4FGB5bNKNGwbXX4p0LqavbqEQgIhKKrbMYmAcMMrOBBAlgAnBqdAcz6+vuq8LFscCbsUVTWgqlpdTVVgKupiERkVBsicDda83sXOBhIBe42d3fMLNpQJm7zwF+aGZjgVrgY2BSXPE02DryqCoCERGItyLA3ecCc1PWXRZ5fAlwSZwxpNo6F4EqAhERyH5n8U7XUBHo8lERkUACE4EqAhGRqAQmAvURiIhEJTARqCIQEYlKYCJQRSAiEpW4RFBbq4pARCQqcYlga0WgRCAiAolMBBswKyAnp1O2QxER2SUkMBFU6h4CEZGIBCaCDWoWEhGJSGAiqNQVQyIiEQlMBKoIRESiEpgIVBGIiEQlLhHU1qoiEBGJSlwiUEUgItJUAhOBKgIRkagEJgLdRyAiEpWoRFBfX4N7jSoCEZGIRCUCjTwqItJcrHMW72o0F4HIp7NlyxbKy8upqqrKdijSgsLCQkpKSujUKfPx1GJNBGY2GvgdkAv8xd1/2cJ+JwF3A4e5e1lc8agiEPl0ysvL6datGwMGDMDMsh2OpHB31qxZQ3l5OQMHDsz4ebE1DZlZLnADMAYYAkw0syFp9usGnAe8GFcsDTQXgcinU1VVRc+ePZUEdlFmRs+ePbe7Youzj2AEsMTdl7p7DTATGJdmvyuBa4DYa01VBCKfnpLArm1Hfj9xJoJ+wIrIcnm4rpGZHQr0d/d/tXYgM5tsZmVmVlZRUbHDAamPQESkuaxdNWRmOcBvgR9va193n+Hupe5e2qtXrx1+zYaKQPcRiLRPa9asYdiwYQwbNow+ffrQr1+/xuWamppWn1tWVsYPf/jDbb7GkUce2VbhthtxdhavBPpHlkvCdQ26AZ8DngpLmT7AHDMbG1eHsSoCkfatZ8+ezJ8/H4CpU6dSVFTEhRde2Li9traWvLz0H2ulpaWUlpZu8zWef/75Nom1PYkzEcwDBpnZQIIEMAE4tWGju68DihuWzewp4EJdNSTSPixefD6VlfPb9JhFRcMYNGj6dj1n0qRJFBYW8uqrrzJy5EgmTJjAeeedR1VVFZ07d+aWW25h8ODBPPXUU1x77bU88MADTJ06leXLl7N06VKWL1/O+eef31gtFBUVUVlZyVNPPcXUqVMpLi5m4cKFDB8+nDvuuAMzY+7cufzoRz+ia9eujBw5kqVLl/LAAw80iWvZsmV861vfYuPGjQBcf/31jdXGNddcwx133EFOTg5jxozhl7/8JUuWLOGss86ioqKC3Nxc7rrrLvbZZ59P/6ZmILZE4O61ZnYu8DDB5aM3u/sbZjYNKHP3OXG9dkuCiiCHnJzOO/ulRSRG5eXlPP/88+Tm5rJ+/XqeffZZ8vLyeOyxx/jZz37GPffc0+w5b731Fk8++SQbNmxg8ODBTJkypdm196+++ipvvPEGe+21FyNHjuS5556jtLSUM888k2eeeYaBAwcyceLEtDH17t2bRx99lMLCQhYvXszEiRMpKyvjwQcf5L777uPFF1+kS5cufPzxxwCcdtppXHzxxYwfP56qqirq6+vb/o1qQaz3Ebj7XGBuyrrLWth3VJyxQMPIo0W66kGkDWzvN/c4ff3rXyc3NxeAdevWcfrpp7N48WLMjC1btqR9zvHHH09BQQEFBQX07t2bDz74gJKSkib7jBgxonHdsGHDWLZsGUVFRXz2s59tvE5/4sSJzJgxo9nxt2zZwrnnnsv8+fPJzc3lnXfeAeCxxx7jjDPOoEuXLgD06NGDDRs2sHLlSsaPHw8EN4XtTIkaYkJzEYh0TF27dm18/POf/5yjjjqKhQsXcv/997d4TX1BQUHj49zcXGpra3don5Zcd9117LnnnixYsICysrJtdmZnU6ISgeYiEOn41q1bR79+wZXqt956a5sff/DgwSxdupRly5YBMGvWrBbj6Nu3Lzk5Odx+++3U1dUBcOyxx3LLLbewadMmAD7++GO6detGSUkJs2fPBqC6urpx+86QsESgikCko7vooou45JJLOOSQQ7brG3ymOnfuzB//+EdGjx7N8OHD6datG927d2+239lnn81tt93G0KFDeeuttxqrltGjRzN27FhKS0sZNmwY1157LQC33347v//97zn44IM58sgjWb16dZvH3hJz9532Ym2htLTUy8p27MKiV1/9Ima5DBv2ZBtHJZIMb775JgcccEC2w8i6yspKioqKcHfOOeccBg0axAUXXJDtsBql+z2Z2cvunvb62YRVBGoaEpFP789//jPDhg3jwAMPZN26dZx55pnZDulTSdww1GoaEpFP64ILLtilKoBPSxWBiEjCJSoR6PJREZHmEpMI3Oupr9+oikBEJEViEkFdXTDehyoCEZGmEpQINAS1SHt31FFH8fDDDzdZN336dKZMmdLic0aNGkXDJefHHXcca9eubbbP1KlTG6/nb8ns2bNZtGhR4/Jll13GY489th3R77oSlAg0BLVIezdx4kRmzpzZZN3MmTNbHPgt1dy5c9l999136LVTE8G0adM45phjduhYu5rEXD6qIahF2tj550M4N0CbGTYMpk9vcfPJJ5/MpZdeSk1NDfn5+Sxbtoz333+f//mf/2HKlCnMmzePzZs3c/LJJ3PFFVc0e/6AAQMoKyujuLiYq6++mttuu43evXvTv39/hg8fDgT3CMyYMYOamhr23Xdfbr/9dubPn8+cOXN4+umnueqqq7jnnnu48sorOeGEEzj55JN5/PHHufDCC6mtreWwww7jxhtvpKCggAEDBnD66adz//33s2XLFu666y7233//JjHtCsNVqyIQkXajR48ejBgxggcffBAIqoFvfOMbmBlXX301ZWVlvPbaazz99NO89tprLR7n5ZdfZubMmcyfP5+5c+cyb968xm0nnngi8+bNY8GCBRxwwAHcdNNNHHnkkYwdO5Zf//rXzJ8/v8kHb1VVFZMmTWLWrFm8/vrr1NbWcuONNzZuLy4u5pVXXmHKlClpm58ahqt+5ZVXmDVrVuO8CNHhqhcsWMBFF10EBMNVn3POOSxYsIDnn3+evn37fro3FVUEIrKjWvnmHqeG5qFx48Yxc+ZMbrrpJgDuvPNOZsyYQW1tLatWrWLRokUcfPDBaY/x7LPPMn78+MahoMeOHdu4beHChVx66aWsXbuWyspKvvrVr7Yaz9tvv83AgQPZb7/9ADj99NO54YYbOP/884EgsQAMHz6ce++9t9nzd4XhqhOTCGprVRGIdATjxo3jggsu4JVXXmHTpk0MHz6c//73v1x77bXMmzePPfbYg0mTJrU4/PS2TJo0idmzZzN06FBuvfVWnnrqqU8Vb8NQ1i0NYx0drrq+vn6nz0UAiWoaUkUg0hEUFRVx1FFH8Z3vfKexk3j9+vV07dqV7t2788EHHzQ2HbXki1/8IrNnz2bz5s1s2LCB+++/v3Hbhg0b6Nu3L1u2bOFvf/tb4/pu3bqxYcOGZscaPHgwy5YtY8mSJUAwiuiXvvSljM9nVxiuOkGJQBWBSEcxceJEFixY0JgIhg4dyiGHHML+++/PqaeeysiRI1t9/qGHHsopp5zC0KFDGTNmDIcddljjtiuvvJLDDz+ckSNHNunYnTBhAr/+9a855JBDePfddxvXFxYWcsstt/D1r3+dgw46iJycHM4666yMz2VXGK46McNQf/TRfaxe/VeGDJlFTk5iWsRE2pSGoW4ftncY6sR8IhYXj6O4eFy2wxAR2eXE2jRkZqPN7G0zW2JmF6fZfpaZvW5m883s32Y2JM54RESkudgSgZnlAjcAY4AhwMQ0H/R/d/eD3H0Y8Cvgt3HFIyJto701JyfNjvx+4qwIRgBL3H2pu9cAM4EmbTPuvj6y2BXQX5jILqywsJA1a9YoGeyi3J01a9Zs9yWocfYR9ANWRJbLgcNTdzKzc4AfAfnA0ekOZGaTgckAe++9d5sHKiKZKSkpoby8nIqKimyHIi0oLCykpKRku56T9c5id78BuMHMTgUuBU5Ps88MYAYEVw3t3AhFpEGnTp0YOHBgtsOQNhZn09BKoH9kuSRc15KZwNdijEdERNKIMxHMAwaZ2UAzywcmAHOiO5jZoMji8cDiGOMREZE0YmsacvdaMzsXeBjIBW529zfMbBpQ5u5zgHPN7BhgC/AJaZqFREQkXu3uzmIzqwDe28ZuxcBHOyGcXY3OO1mSet6Q3HP/NOf9GXfvlW5Du0sEmTCzspZupe7IdN7JktTzhuSee1znnZhB50REJD0lAhGRhOuoiWBGtgPIEp13siT1vCG55x7LeXfIPgIREclcR60IREQkQ0oEIiIJ1+ESwbbmQOgozOxmM/vQzBZG1vUws0fNbHH47x7ZjDEOZtbfzJ40s0Vm9oaZnReu79DnbmaFZvaSmS0Iz/uKcP1AM3sx/HufFd7F3+GYWa6ZvWpmD4TLHf68zWxZZL6WsnBdLH/nHSoRZDgHQkdxKzA6Zd3FwOPuPgh4PFzuaGqBH7v7EODzwDnh77ijn3s1cLS7DwWGAaPN7PPANcB17r4vwd35381eiLE6D3gzspyU8z7K3YdF7h2I5e+8QyUCMpgDoaNw92eAj1NWjwNuCx/fRgccxM/dV7n7K+HjDQQfDv3o4OfugcpwsVP44wRDt98dru9w5w1gZiUEY5H9JVw2EnDeLYjl77yjJYJ0cyD0y1Is2bCnu68KH68G9sxmMHEzswHAIcCLJODcw+aR+cCHwKPAu8Bad68Nd+mof+/TgYuA+nC5J8k4bwceMbOXwzlZIKa/86zPRyDxcHc3sw57bbCZFQH3AOe7+/rgS2Kgo567u9cBw8xsd+CfwP7ZjSh+ZnYC8KG7v2xmo7Iczs72BXdfaWa9gUfN7K3oxrb8O+9oFcH2zoHQ0XxgZn0Bwn8/zHI8sTCzTgRJ4G/ufm+4OhHnDuDua4EngSOA3c2s4QtdR/x7HwmMNbNlBE29RwO/o+OfN+6+Mvz3Q4LEP4KY/s47WiLY5hwIHdwctg7lfTpwXxZjiUXYPnwT8Ka7/zayqUOfu5n1CisBzKwzcCxB/8iTwMnhbh3uvN39EncvcfcBBP+fn3D30+jg521mXc2sW8Nj4CvAQmL6O+9wdxab2XEEbYoNcyBcnd2I4mFm/wBGEQxL+wFwOTAbuBPYm2Co7m+4e2qHcrtmZl8AngVeZ2ub8c8I+gk67Lmb2cEEnYO5BF/g7nT3aWb2WYJvyj2AV4Fvunt19iKNT9g0dKG7n9DRzzs8v3+Gi3nA3939ajPrSQx/5x0uEYiIyPbpaE1DIiKynZQIREQSTolARCThlAhERBJOiUBEJOGUCERCZlYXjvTY8NNmA9eZ2YDoSLEiuxINMSGy1WZ3H5btIER2NlUEItsQjgv/q3Bs+JfMbN9w/QAze8LMXjOzx81s73D9nmb2z3DugAVmdmR4qFwz+3M4n8Aj4R3CmNkPw/kVXjOzmVk6TUkwJQKRrTqnNA2dEtm2zt0PAq4nuHMd4A/Abe5+MPA34Pfh+t8DT4dzBxwKvBGuHwTc4O4HAmuBk8L1FwOHhMc5K55TE2mZ7iwWCZlZpbsXpVm/jGBSmKXhgHer3b2nmX0E9HX3LeH6Ve5ebGYVQEl0yINwyOxHwwlFMLOfAp3c/SozewioJBgiZHZk3gGRnUIVgUhmvIXH2yM6Fk4dW/vojieYWe9QYF5kVE2RnUKJQCQzp0T+fSF8/DzBiJgApxEMhgfBFIJToHEyme4tHdTMcoD+7v4k8FOgO9CsKhGJk755iGzVOZwBrMFD7t5wCekeZvYawbf6ieG6HwC3mNlPgArgjHD9ecAMM/suwTf/KcAq0ssF7giThQG/D+cbENlp1Ecgsg1hH0Gpu3+U7VhE4qCmIRGRhFNFICKScKoIREQSTolARCThlAhERBJOiUBEJOGUCEREEu7/AzHZq8/xwUZcAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "plt.plot(epochs, acc, 'y', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3eb3cba9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.104908</td>\n",
       "      <td>0.316770</td>\n",
       "      <td>2.152408</td>\n",
       "      <td>0.493827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.739106</td>\n",
       "      <td>0.756211</td>\n",
       "      <td>0.205756</td>\n",
       "      <td>0.962963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.210362</td>\n",
       "      <td>0.940994</td>\n",
       "      <td>0.117513</td>\n",
       "      <td>0.944444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.128881</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.047211</td>\n",
       "      <td>0.987654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.056407</td>\n",
       "      <td>0.984472</td>\n",
       "      <td>0.016594</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.031146</td>\n",
       "      <td>0.993789</td>\n",
       "      <td>0.035747</td>\n",
       "      <td>0.993827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.041192</td>\n",
       "      <td>0.987578</td>\n",
       "      <td>0.034469</td>\n",
       "      <td>0.993827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.071865</td>\n",
       "      <td>0.976708</td>\n",
       "      <td>0.035266</td>\n",
       "      <td>0.987654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.033629</td>\n",
       "      <td>0.993789</td>\n",
       "      <td>0.018728</td>\n",
       "      <td>0.993827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.010373</td>\n",
       "      <td>0.996894</td>\n",
       "      <td>0.015937</td>\n",
       "      <td>0.993827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.005934</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.008723</td>\n",
       "      <td>0.993827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.002518</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.005559</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.001667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.005080</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.001380</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.005228</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.001193</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.004420</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.001073</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.004822</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.000961</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.003873</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.000871</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.004605</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.000782</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.003958</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.000728</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.004556</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.000684</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.004419</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.000640</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.003564</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.000576</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.003603</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.000557</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.003664</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.000511</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.003121</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.000478</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.003616</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.000454</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.003193</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.000417</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.002980</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.000409</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.003184</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.000367</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.003120</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.000363</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.003066</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.000338</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.002977</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.000323</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.002874</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.000309</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.002807</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.000298</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.002990</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.000274</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.002307</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.000267</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.002342</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.000245</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.002372</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.000234</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.002341</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.000228</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.002537</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.000221</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.002118</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.000209</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.002007</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.000211</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.002303</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.000199</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.002056</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.000187</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.001991</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.000181</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.001892</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.000175</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.001984</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.000172</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.001993</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.000156</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.001644</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.000162</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.002057</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        loss  accuracy  val_loss  val_accuracy\n",
       "0   9.104908  0.316770  2.152408      0.493827\n",
       "1   0.739106  0.756211  0.205756      0.962963\n",
       "2   0.210362  0.940994  0.117513      0.944444\n",
       "3   0.128881  0.964286  0.047211      0.987654\n",
       "4   0.056407  0.984472  0.016594      1.000000\n",
       "5   0.031146  0.993789  0.035747      0.993827\n",
       "6   0.041192  0.987578  0.034469      0.993827\n",
       "7   0.071865  0.976708  0.035266      0.987654\n",
       "8   0.033629  0.993789  0.018728      0.993827\n",
       "9   0.010373  0.996894  0.015937      0.993827\n",
       "10  0.005934  1.000000  0.008723      0.993827\n",
       "11  0.002518  1.000000  0.005559      1.000000\n",
       "12  0.001667  1.000000  0.005080      1.000000\n",
       "13  0.001380  1.000000  0.005228      1.000000\n",
       "14  0.001193  1.000000  0.004420      1.000000\n",
       "15  0.001073  1.000000  0.004822      1.000000\n",
       "16  0.000961  1.000000  0.003873      1.000000\n",
       "17  0.000871  1.000000  0.004605      1.000000\n",
       "18  0.000782  1.000000  0.003958      1.000000\n",
       "19  0.000728  1.000000  0.004556      1.000000\n",
       "20  0.000684  1.000000  0.004419      1.000000\n",
       "21  0.000640  1.000000  0.003564      1.000000\n",
       "22  0.000576  1.000000  0.003603      1.000000\n",
       "23  0.000557  1.000000  0.003664      1.000000\n",
       "24  0.000511  1.000000  0.003121      1.000000\n",
       "25  0.000478  1.000000  0.003616      1.000000\n",
       "26  0.000454  1.000000  0.003193      1.000000\n",
       "27  0.000417  1.000000  0.002980      1.000000\n",
       "28  0.000409  1.000000  0.003184      1.000000\n",
       "29  0.000367  1.000000  0.003120      1.000000\n",
       "30  0.000363  1.000000  0.003066      1.000000\n",
       "31  0.000338  1.000000  0.002977      1.000000\n",
       "32  0.000323  1.000000  0.002874      1.000000\n",
       "33  0.000309  1.000000  0.002807      1.000000\n",
       "34  0.000298  1.000000  0.002990      1.000000\n",
       "35  0.000274  1.000000  0.002307      1.000000\n",
       "36  0.000267  1.000000  0.002342      1.000000\n",
       "37  0.000245  1.000000  0.002372      1.000000\n",
       "38  0.000234  1.000000  0.002341      1.000000\n",
       "39  0.000228  1.000000  0.002537      1.000000\n",
       "40  0.000221  1.000000  0.002118      1.000000\n",
       "41  0.000209  1.000000  0.002007      1.000000\n",
       "42  0.000211  1.000000  0.002303      1.000000\n",
       "43  0.000199  1.000000  0.002056      1.000000\n",
       "44  0.000187  1.000000  0.001991      1.000000\n",
       "45  0.000181  1.000000  0.001892      1.000000\n",
       "46  0.000175  1.000000  0.001984      1.000000\n",
       "47  0.000172  1.000000  0.001993      1.000000\n",
       "48  0.000156  1.000000  0.001644      1.000000\n",
       "49  0.000162  1.000000  0.002057      1.000000"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_hist = pd.DataFrame(history.history)\n",
    "train_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dda6a1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d878c526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix :\n",
      "\n",
      "\n",
      "[[19  1  0  0  0  0]\n",
      " [ 0 20  0  0  0  0]\n",
      " [ 0  0 20  0  0  0]\n",
      " [ 0  0  0 20  0  0]\n",
      " [ 0  0  0  0 12  0]\n",
      " [ 0  0  0  0  0 20]]\n",
      "\n",
      "\n",
      "Classification Report : \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.97        20\n",
      "           1       0.95      1.00      0.98        20\n",
      "           2       1.00      1.00      1.00        20\n",
      "           3       1.00      1.00      1.00        20\n",
      "           4       1.00      1.00      1.00        12\n",
      "           5       1.00      1.00      1.00        20\n",
      "\n",
      "    accuracy                           0.99       112\n",
      "   macro avg       0.99      0.99      0.99       112\n",
      "weighted avg       0.99      0.99      0.99       112\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Confusion matrix to calculate accuracy for each class\n",
    "ytrue = np.argmax(ytest,axis=1)\n",
    "ypred = np.argmax(h_model.predict(xtest),axis=1)\n",
    "print('\\nConfusion Matrix :\\n\\n')\n",
    "print(confusion_matrix(ytrue,ypred))\n",
    "print('\\n\\nClassification Report : \\n\\n',classification_report(ytrue,ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "db81924f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_units': 224,\n",
       " 'activation': 'tanh',\n",
       " 'n_layers': 2,\n",
       " 'conv_0_units': 224,\n",
       " 'dropout': 0.05,\n",
       " 'conv_1_units': 224,\n",
       " 'conv_2_units': 128}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuner.get_best_hyperparameters()[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4783c963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "_, train_acc = h_model.evaluate(xtrain, ytrain, verbose=0)\n",
    "_, test_acc = h_model.evaluate(xtest, ytest, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "67d1c183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 1.000, Test: 0.991\n"
     ]
    }
   ],
   "source": [
    "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3258324b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 18ms/step - loss: 0.0114 - accuracy: 0.9911\n",
      "[0.011419768445193768, 0.9910714030265808]\n"
     ]
    }
   ],
   "source": [
    "predictions = h_model.predict(xtest)\n",
    "score = h_model.evaluate(xtest, ytest)\n",
    "print(score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
